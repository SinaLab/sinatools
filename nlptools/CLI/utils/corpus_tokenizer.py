"""

About:
------

The sina_corpus_tokenizer tool offers functionality to tokenize a corpus and write the results to a CSV file. It recursively searches through a specified directory for text files, tokenizes the content, and outputs the results, including various metadata, to a specified CSV file.

Usage:
-------

Below is the usage information that can be generated by running sina_corpus_tokenizer --help.

.. code-block:: none

    Usage:
        sina_corpus_tokenizer dir_path output_csv

.. code-block:: none

    Positional Arguments:
    dir_path
            The path to the directory containing the text files.

    output_csv
            The path to the output CSV file.

Examples:
---------

.. code-block:: none

    sina_corpus_tokenizer --dir_path "/path/to/text/directory/of/files" --output_csv  "outputFile.csv"

Note:
-----

.. code-block:: none

    - The tool only processes text files (with a .txt extension).
    - The output CSV will contain the following columns:                
        - 'Row_ID' (a unique identifier for each records in outputfile)
        - 'Docs_Sentence_Word_ID' (a concatenated identifier comprising directory name, file name, global sentence id, sentence id, and word position).
        - 'GlobalSentenceID' (Integer, a unique identifier for each sentence in the entire file)
        - 'SentenceID' (Integer, a unique identifier for each file within the CSV file)
        - 'Sentence' (Generated text that forms a sentence)
        - 'Word Position' (Integer, the position of each word within the sentence)
        - 'Word' (Each row contains a word from the generated sentence).
    - Ensure that the text files are appropriately encoded in UTF-8 or compatible formats.
    - The tool uses the `nltk` library for sentence and word tokenization. Make sure to have the library installed in your environment.
"""

import argparse
from nlptools.utils.corpus_tokenizer import corpus_tokenizer

# Define the main function that will parse the arguments
def main():
    # Create an ArgumentParser object
    parser = argparse.ArgumentParser(description='Tokenize the corpus and write the results to a CSV file.')
    
    # Add arguments to the parser
    parser.add_argument('--dir_path', type=str, help='The path to the directory containing the text files.')
    parser.add_argument('--output_csv', type=str, help='The path to the output CSV file.')
    
    # Parse the command-line arguments
    args = parser.parse_args()
    
    # Call the corpus_tokenizer function with the parsed arguments
    corpus_tokenizer(args.dir_path, args.output_csv)

# Call the main function when the script is executed
if __name__ == '__main__':
    main()

#sina_corpus_tokenizer /path/to/text/files output.csv
